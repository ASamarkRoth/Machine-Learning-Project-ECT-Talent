{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Fully-Connected Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load code for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fcnn.train\n",
    "import fcnn.eval\n",
    "import data_processing.data as dp\n",
    "%autoreload 1\n",
    "%aimport fcnn.train\n",
    "%aimport fcnn.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = './data_processing/voxels/'\n",
    "train, _ = dp.load_discretized_data(path_data, prefix='Grid20', categorical=False, binary=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (train[0].toarray(), train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to clear the logs in the tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf fcnn/logs/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the FCNN model is generic in a sense that one can choose the number of hidden layers, number of neurons in each layer as well as if one wants to apply dropout and at which probability. In the training, only one hidden layer was considered. An excerpt from the implemented code may be seen below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(hidden_layers[0], input_dim=train[FEATURES].shape[1], activation='relu'))\n",
    "if use_dropout:\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "for neurons in hidden_layers[1:]:\n",
    "    model.add(tf.keras.layers.Dense(neurons, input_dim=train[FEATURES].shape[1], activation='relu'))\n",
    "    if use_dropout:\n",
    "        model.add(tf.keras.layers.Dropout(dropout))\n",
    "model.add(tf.keras.layers.Dense(num_categories, activation='sigmoid'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See also**: [fcnn/train.py](./fcnn/train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following strategy was applied when training the model:\n",
    "\n",
    "## A 'simple' start:\n",
    "\n",
    "* A subset of the data was only included in the training, e.g. 160 samples\n",
    "* No regularization, i.e. dropout not activated\n",
    "* A limited number of neurons were included, e.g. 32\n",
    "* Started with a learning rate of 1e-5, taken from [Kuchera, 2019](https://www.sciencedirect.com/science/article/pii/S0168900219308046?via%3Dihub)\n",
    "* I strived to just be able to train the model, i.e. observe a decreasing loss function with the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fcnn.train.train(train=train, \n",
    "                log_dir='fcnn/logs/',\n",
    "                hidden_layers=[32],\n",
    "                validation_split=0.15,\n",
    "                lr=1e-5, \n",
    "                decay=0.,\n",
    "                examples_limit=-160,\n",
    "                epochs=20, \n",
    "                batch_size=32,\n",
    "                seed=71,\n",
    "                use_dropout=False,\n",
    "                dropout=0.5,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir fcnn/logs/ --port 6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was really no issue training the model (loss was steadily decreasing), see tensorboard above, therefore a further advanced model was trained:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards final model:\n",
    "\n",
    "* All data included\n",
    "* No regularization, i.e. dropout not activated\n",
    "* 128 neurons were included\n",
    "* A faster learning rate of 1e-3 (tuned)\n",
    "* Now striving to train the model smoothly, tuning the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fcnn.train.train(train=train, \n",
    "                log_dir='fcnn/logs/',\n",
    "                hidden_layers=[128],\n",
    "                validation_split=0.15,\n",
    "                lr=1e-3, \n",
    "                decay=0.,\n",
    "                examples_limit=-1,\n",
    "                epochs=20, \n",
    "                batch_size=32,\n",
    "                seed=71,\n",
    "                use_dropout=False,\n",
    "                dropout=0.5,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir fcnn/logs/ --port 6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was again no issue training the model, see tensorboard above. The model converged very fast and since the loss of the validation function does not increase after a while, there should be limited overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model:\n",
    "\n",
    "* All data included\n",
    "* Dropout activated\n",
    "* 128 neurons were included\n",
    "* A learning rate of 1e-3 (tuned)\n",
    "* Running only 12 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fcnn.train.train(train=train, \n",
    "                log_dir='fcnn/logs/',\n",
    "                hidden_layers=[128],\n",
    "                validation_split=0.15,\n",
    "                lr=1e-3, \n",
    "                decay=0.,\n",
    "                examples_limit=-1,\n",
    "                epochs=12, \n",
    "                batch_size=32,\n",
    "                seed=71,\n",
    "                use_dropout=True,\n",
    "                dropout=0.5,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir fcnn/logs/ --port 6008"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
