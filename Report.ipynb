{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Author**: Anton SÃ¥mark-Roth <br>\n",
    "Mail: <a href=\"mailto:anton.samark-roth@nuclear.lu.se\">anton.samark-roth@nuclear.lu.se</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Report - AT-TPC project\n",
    "Machine Learning and Data Analysis for Nuclear Physics, a Nuclear TALENT Course at the ECT*, June 22 to July 3 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Report\" data-toc-modified-id=\"Report-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Report</a></span><ul class=\"toc-item\"><li><span><a href=\"#About-this-notebook\" data-toc-modified-id=\"About-this-notebook-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>About this notebook</a></span></li></ul></li><li><span><a href=\"#Examining-the-data\" data-toc-modified-id=\"Examining-the-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Examining the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-of-interest---Lifetimes-in-decay-chains\" data-toc-modified-id=\"Data-of-interest---Lifetimes-in-decay-chains-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data of interest - Lifetimes in decay chains</a></span></li><li><span><a href=\"#Motivation---Do-all-decay-chains-in-a-set-have-a-common-origin?\" data-toc-modified-id=\"Motivation---Do-all-decay-chains-in-a-set-have-a-common-origin?-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Motivation - Do all decay chains in a set have a common origin?</a></span></li></ul></li><li><span><a href=\"#Schmidt-tests-on-the-set-of-short-E115-decay-chains\" data-toc-modified-id=\"Schmidt-tests-on-the-set-of-short-E115-decay-chains-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Schmidt tests on the set of short E115 decay chains</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Schmidt-test\" data-toc-modified-id=\"The-Schmidt-test-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Schmidt test</a></span></li><li><span><a href=\"#Generalised-Schmidt-test\" data-toc-modified-id=\"Generalised-Schmidt-test-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generalised Schmidt test</a></span></li><li><span><a href=\"#The-generalised-Schmidt-method-applied\" data-toc-modified-id=\"The-generalised-Schmidt-method-applied-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>The generalised Schmidt method applied</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simulation-of-expected-values-and-confidence-intervals\" data-toc-modified-id=\"Simulation-of-expected-values-and-confidence-intervals-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Simulation of expected values and confidence intervals</a></span></li></ul></li><li><span><a href=\"#Summary-Generalised-Schmidt-Method\" data-toc-modified-id=\"Summary-Generalised-Schmidt-Method-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Summary Generalised Schmidt Method</a></span></li></ul></li><li><span><a href=\"#Figure-of-Merit-(FoM)-method\" data-toc-modified-id=\"Figure-of-Merit-(FoM)-method-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Figure-of-Merit (FoM) method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simulations\" data-toc-modified-id=\"Simulations-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Simulations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simulating-sets-of-decay-chains\" data-toc-modified-id=\"Simulating-sets-of-decay-chains-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Simulating sets of decay chains</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Random-sampling-of-$\\tau$-from-its-likelihood-function\" data-toc-modified-id=\"1.-Random-sampling-of-$\\tau$-from-its-likelihood-function-4.1.1.1\"><span class=\"toc-item-num\">4.1.1.1&nbsp;&nbsp;</span>1. Random sampling of $\\tau$ from its likelihood function</a></span></li><li><span><a href=\"#2.-Simulating-100-000-sets-of-decay-chains-AND-calculating-their-FoM-values.\" data-toc-modified-id=\"2.-Simulating-100-000-sets-of-decay-chains-AND-calculating-their-FoM-values.-4.1.1.2\"><span class=\"toc-item-num\">4.1.1.2&nbsp;&nbsp;</span>2. Simulating 100 000 sets of decay chains AND calculating their FoM values.</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Summary</a></span></li></ul></li></ul></li><li><span><a href=\"#The-alleged-link-between-Element-117-and-115\" data-toc-modified-id=\"The-alleged-link-between-Element-117-and-115-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>The alleged link between Element 117 and 115</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracting-data\" data-toc-modified-id=\"Extracting-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Extracting data</a></span></li><li><span><a href=\"#(i)-Calculations\" data-toc-modified-id=\"(i)-Calculations-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>(i) Calculations</a></span></li><li><span><a href=\"#(ii)-Simulations\" data-toc-modified-id=\"(ii)-Simulations-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>(ii) Simulations</a></span></li><li><span><a href=\"#Results-and-Conclusions\" data-toc-modified-id=\"Results-and-Conclusions-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Results and Conclusions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "The main objective is to classify events aquired from an Active Target (simulated data), as being \"beam\" or \"reaction\" events. The idea is to implement a \"software trigger\" which would be able to effectively select only relevant data to save on disk for future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the writeup, the ML model will quickly determine whether or not a reaction occured -- this can be added into the experiment as a \"software trigger\", which helps write only interesting events to disk.\n",
    "\n",
    "the 22Mg experiment, was a 22Mg beam incident on alpha particles, i.e. He gas in the detector volume.\n",
    "\n",
    "They looked for excited states in the 22Mg+ alpha combined system to better understand the nuclear structure (edited) \n",
    "\n",
    "But, in principle, this model could be used for any future experiment using the AT-TPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "We will apply the ML techiques learned during the Talent Course, in order to analyse the data and reach the best performance possible.<br>\n",
    "First there will be a section dedicated to data visualization, and in which we will discuss the general characteristic of the task. Afterwards, we will propose various approaches to tackle to problem, and show the results for each methods. Eventually, we will summarize and discuss the outcomes in the final section.\n",
    "\n",
    "Models used in this project:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Dense Neural Networks DNN\n",
    "- K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format\n",
    "Data are saved in the file \"Mg22_alphaalpha_digiSim.h5\", which contains 2000 simulated events: even numbers are \"reaction\" events, while odd numbers are \"beam\" event.<br>\n",
    "Each event is constitued by a point cloud of the active pads for that event.<br>\n",
    "In turn, every hit pad is associated with a 4-tuple (x,y,z,q): x and y are the position of the hit pad on the detector plane, z is the coordinare associated to the beam axis, and q is the charge deposited on the pad.<br> \n",
    "Actually, there is an extra column associated with time (not needed since data already contains the z coordinate thanks to a pre-processing phase), and also an extra column of zeros, unnecessary for this analysis.<br>\n",
    "The number of hit pads may vary for each event, ranging from around 20, up to a few hundred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-aways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or how to present the data to the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import fcnn.eval\n",
    "import cnn.eval\n",
    "import logistic.eval\n",
    "import data_processing.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data_processing/voxels/\"\n",
    "# Load data\n",
    "_, test_voxels = data_processing.data.load_discretized_data(data_dir, prefix='', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = './data_processing/images/xyimages.h5'\n",
    "_, test_images = data_processing.data.load_image_h5(path_data, categorical=False, binary=True, reverse_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with $l^2$ regularization\n",
    "\n",
    "The classification report along with the confusion matrix of the logistic regression model with $l^2$ regularization based on the test data can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "logistic.eval.eval(model_file='logistic/logs/logistic_cv_model.pkl', data=test_voxels, name=\"LogisticCVRegression\", examples_limit=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected neural network\n",
    "\n",
    "The classification report along with the confusion matrix of the fully-connected neural network based on the test data can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn.eval.eval(model_file='fcnn/logs/nodes128_dropoutTrue_lr0.001_decay0.0_samples-1/20200826-093241/saved_model.h5', data=test_voxels, name='FCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network\n",
    "\n",
    "The classification report along with the confusion matrix of the convolutional neural network based on the test data can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval.eval(model_file='fcnn/logs/nodes128_dropoutTrue_lr0.001_decay0.0_samples-1/20200826-093241/saved_model.h5', data=test_voxels, name='FCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "livereveal": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "567px",
    "left": "0px",
    "right": "1108px",
    "top": "111px",
    "width": "193px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
